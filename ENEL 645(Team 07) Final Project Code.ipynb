{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "%matplotlib qt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense,Activation,Input\n",
    "from tensorflow.keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of categories =  ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___healthy', 'Potato___Late_blight', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_healthy', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_mosaic_virus', 'Tomato__Tomato_YellowLeaf__Curl_Virus'] \n",
      "\n",
      "No. of categories =  15\n"
     ]
    }
   ],
   "source": [
    "fpath = r\"C:\\Users\\tonyj\\Downloads\\archive\\PlantVillage\"\n",
    "random_seed = 111\n",
    "\n",
    "categories = os.listdir(fpath)\n",
    "print(\"List of categories = \",categories,\"\\n\\nNo. of categories = \", len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images loaded =  16285 \n",
      "No. of labels loaded =  16285\n",
      "<class 'list'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "def load_images_and_labels(categories):\n",
    "    img_lst=[]\n",
    "    labels=[]\n",
    "    for index, category in enumerate(categories):\n",
    "        for image_name in os.listdir(fpath+\"/\"+category)[300:]:\n",
    "            file_ext = image_name.split(\".\")[-1]\n",
    "            if (file_ext.lower() == \"jpg\") or (file_ext.lower() == \"jpeg\"):\n",
    "                #print(f\"\\nCategory = {category}, Image name = {image_name}\")\n",
    "                img = cv2.imread(fpath+\"/\"+category+\"/\"+image_name)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                img_array = Image.fromarray(img, 'RGB')\n",
    "\n",
    "                #resize image 100 X 100\n",
    "                resized_img = img_array.resize((100, 100))\n",
    "\n",
    "                img_lst.append(np.array(resized_img))\n",
    "\n",
    "                labels.append(index)\n",
    "    return img_lst, labels\n",
    "\n",
    "images, labels = load_images_and_labels(categories)\n",
    "print(\"No. of images loaded = \",len(images),\"\\nNo. of labels loaded = \",len(labels))\n",
    "print(type(images),type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape =  (16285, 100, 100, 3) \n",
      "Labels shape =  (16285,)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Images shape = \",images.shape,\"\\nLabels shape = \",labels.shape)\n",
    "print(type(images),type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here some random images are displayed\n",
    "def display_rand_images(images, labels):\n",
    "    plt.figure(1 , figsize = (19 , 10))\n",
    "    n = 0 \n",
    "    for i in range(9):\n",
    "        n += 1 \n",
    "        r = np.random.randint(0 , images.shape[0] , 1)\n",
    "        \n",
    "        plt.subplot(3 , 3 , n)\n",
    "        plt.subplots_adjust(hspace = 0.3 , wspace = 0.3)\n",
    "        plt.imshow(images[r[0]])\n",
    "        \n",
    "        plt.title('Plant label : {}'.format(labels[r[0]]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "display_rand_images(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set\n",
      "Images:  (12213, 100, 100, 3)\n",
      "Labels shape:  (12213,)\n",
      "\n",
      "Validation set\n",
      "Images:  (1629, 100, 100, 3)\n",
      "Labels shape:  (1629,)\n",
      "\n",
      " Test set\n",
      "Images:  (2443, 100, 100, 3)\n",
      "Labels shape:  (2443,)\n"
     ]
    }
   ],
   "source": [
    "(X_dev, Y_dev)=(images,labels)\n",
    "indexes = np.arange(X_dev.shape[0], dtype = int)\n",
    "np.random.shuffle(indexes)\n",
    "X_dev = X_dev[indexes]\n",
    "Y_dev = Y_dev[indexes]\n",
    "\n",
    "nsplit1 = int(0.75*X_dev.shape[0]) # Train/validation split\n",
    "nsplit2 = int(0.85*X_dev.shape[0]) # Test/validation split\n",
    "\n",
    "# Train and validation split\n",
    "X_train = X_dev[:nsplit1]\n",
    "Y_train = Y_dev[:nsplit1]\n",
    "X_val = X_dev[nsplit1:nsplit2]\n",
    "Y_val = Y_dev[nsplit1:nsplit2]\n",
    "# Test set\n",
    "X_test = X_dev[nsplit2:]\n",
    "Y_test = Y_dev[nsplit2:]\n",
    "\n",
    "print(\"\\nTrain set\")\n",
    "print(\"Images: \",X_train.shape)#prints the total no of images in the training set\n",
    "print(\"Labels shape: \",Y_train.shape)\n",
    "print(\"\\nValidation set\")\n",
    "print(\"Images: \",X_val.shape)#prints the total no of images in the validation set\n",
    "print(\"Labels shape: \",Y_val.shape)\n",
    "print(\"\\n Test set\")\n",
    "print(\"Images: \",X_test.shape)#prints the total no of images in the test set\n",
    "print(\"Labels shape: \",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data scaling\n",
    "norm_type=0\n",
    "if norm_type==0:\n",
    "   X_train=X_train/255\n",
    "   X_val=X_val/255\n",
    "   X_test=X_test/255\n",
    "elif norm_type==1:\n",
    "     train_mean=X_train.mean()\n",
    "     train_std =X_train.std()\n",
    "     X_train=(X_train-train_mean)/(X_train-train_std)\n",
    "     X_val=(X_val-train_mean)/(X_train-train_std)\n",
    "     X_test=(X_test-train_mean)/(X_train-train_std)\n",
    "else: \n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  7 14  8  7]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding\n",
    "Y_train_oh=to_categorical(Y_train)\n",
    "Y_val_oh=to_categorical(Y_val)\n",
    "Y_test_oh=to_categorical(Y_test)\n",
    "print(Y_train[:5])\n",
    "print(Y_train_oh[:5])\n",
    "k=np.unique(Y_dev).size\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(ishape = (100,100,3),k = 15, lr = 1e-4):#defines a function named my_model which creates a CNN model as specified\n",
    "    model_input = tf.keras.layers.Input(shape = ishape)\n",
    "    l1 = tf.keras.layers.Conv2D(48, (3,3), padding='same', activation='relu')(model_input)\n",
    "    l1_drop = tf.keras.layers.Dropout(0.25)(l1)\n",
    "    l2 = tf.keras.layers.MaxPool2D((2,2))(l1_drop)\n",
    "    l3 = tf.keras.layers.Conv2D(96, (3,3), padding='same', activation='relu')(l2)\n",
    "    l4 = tf.keras.layers.Conv2D(96, (3,3), padding='same', activation='relu')(l3)\n",
    "    l4_drop = tf.keras.layers.Dropout(0.25)(l4)\n",
    "    flat = tf.keras.layers.Flatten()(l4_drop)\n",
    "    out = tf.keras.layers.Dense(k,activation = 'softmax')(flat)\n",
    "    model = tf.keras.models.Model(inputs = model_input, outputs = out)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining callbacks\n",
    "# First, We create an early-stop that monitors the validation loss and stops the training after 20 epochs if there is no improvement to prevent overfitting.\n",
    "model_name=\"leafdisease_classification.h5\"\n",
    "early_stop=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=20)\n",
    "monitor=tf.keras.callbacks.ModelCheckpoint(model_name,monitor=\"val_loss\",\\\n",
    "                                          verbose=0,save_best_only=True,\\\n",
    "                                          save_weights_only=True,mode='min')\n",
    "# We then define a learning rate scheduler that reduces the learning rate by half after every 10 epochs\n",
    "def scheduler(epoch,lr):\n",
    "    if epoch%10==0:\n",
    "        lr=lr/2\n",
    "    return lr\n",
    "lr_schedule=tf.keras.callbacks.LearningRateScheduler(scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 100, 100, 48)      1344      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100, 100, 48)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 96)        41568     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 50, 50, 96)        83040     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50, 50, 96)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 240000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                3600015   \n",
      "=================================================================\n",
      "Total params: 3,725,967\n",
      "Trainable params: 3,725,967\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "382/382 [==============================] - 220s 573ms/step - loss: 1.9281 - accuracy: 0.3917 - val_loss: 1.0550 - val_accuracy: 0.6630\n",
      "Epoch 2/5\n",
      "382/382 [==============================] - 234s 613ms/step - loss: 0.8085 - accuracy: 0.7394 - val_loss: 0.7161 - val_accuracy: 0.7839\n",
      "Epoch 3/5\n",
      "382/382 [==============================] - 238s 624ms/step - loss: 0.5677 - accuracy: 0.8252 - val_loss: 0.6534 - val_accuracy: 0.8005\n",
      "Epoch 4/5\n",
      "382/382 [==============================] - 230s 601ms/step - loss: 0.4608 - accuracy: 0.8524 - val_loss: 0.7574 - val_accuracy: 0.7366\n",
      "Epoch 5/5\n",
      "382/382 [==============================] - 215s 564ms/step - loss: 0.3754 - accuracy: 0.8810 - val_loss: 0.4867 - val_accuracy: 0.8478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x205d31aee50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=my_model()\n",
    "model.summary()#gives the summary of the model\n",
    "# We train our model for 5 epochs with a batch size of 32\n",
    "model.fit(X_train,Y_train_oh,batch_size=32,epochs=5,verbose=1,callbacks=[early_stop,monitor,lr_schedule],\n",
    "          validation_data=(X_val,Y_val_oh),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 5s 70ms/step - loss: 0.4627 - accuracy: 0.8502\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(model_name)\n",
    "metrics = model.evaluate(X_test,Y_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2443, 15)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code that displays images which were wrongly predicted\n",
    "plt.figure(1 , figsize = (19 , 10))\n",
    "n = 0 \n",
    "\n",
    "for i in range(9):\n",
    "    n += 1 \n",
    "    r = np.random.randint( 0, X_test.shape[0], 1)\n",
    "    \n",
    "    plt.subplot(3, 3, n)\n",
    "    plt.subplots_adjust(hspace = 0.3, wspace = 0.3)\n",
    "    \n",
    "    plt.imshow(X_test[r[0]])\n",
    "    plt.title('Actual = {}, Predicted = {}'.format(Y_test[r[0]] , Y_test[r[0]]*pred[r[0]][Y_test[r[0]]]) )\n",
    "    plt.xticks([]) , plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
